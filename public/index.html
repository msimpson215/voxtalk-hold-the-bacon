<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>VoxTalk Safe Mode</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body {
      margin:0; font-family:system-ui,sans-serif;
      display:grid; place-items:center; min-height:100vh;
      background:#111; color:#eee;
    }
    h1 { font-size:22px; }
    p { font-size:14px; }
  </style>
</head>
<body>
  <h1>VoxTalk (Push-to-Talk)</h1>
  <p>Hold SPACEBAR to talk (auto-stops after 30s)</p>
  <audio id="remote" autoplay playsinline></audio>

  <script>
    const rtAudio = document.getElementById('remote');
    let pc, dc, micTrack, timeoutId;

    async function initRealtime() {
      console.log("ðŸ”„ Fetching session...");
      const s = await fetch("/session", { method:"POST" });
      const { client_secret, model, voice } = await s.json();
      console.log("âœ… Session ready");

      pc = new RTCPeerConnection();
      pc.ontrack = (ev)=> { rtAudio.srcObject = ev.streams[0]; };

      dc = pc.createDataChannel("events");
      dc.onopen = () => {
        console.log("ðŸ“¡ Data channel open");

        // Force session to always reply, and allow interruption
        dc.send(JSON.stringify({
          type:"session.update",
          session:{
            voice:"verse",
            modalities:["audio","text"],
            turn_detection:null,
            interrupt_response:true   // ðŸ‘ˆ interruptible
          }
        }));

        // Kick it off
        dc.send(JSON.stringify({
          type:"response.create",
          response:{ instructions:"Hello! Hold spacebar to talk." }
        }));
      };

      dc.onmessage = (e)=> {
        console.log("ðŸ“¡ Raw event:", e.data);
        try {
          const evt = JSON.parse(e.data);
          if (evt.type === "response.message.delta") {
            const chunk = evt.delta.map(d=>d.content?.[0]?.text||"").join("");
            if (chunk) console.log("ðŸ§  AI:", chunk);
          }
        } catch {}
      };

      const offer = await pc.createOffer({ offerToReceiveAudio:true });
      await pc.setLocalDescription(offer);

      const r = await fetch(
        `https://api.openai.com/v1/realtime?model=${encodeURIComponent(model)}&voice=${voice}`,
        {
          method:"POST",
          headers:{ "Authorization":`Bearer ${client_secret.value}`, "Content-Type":"application/sdp" },
          body: offer.sdp
        }
      );
      const answer = { type:"answer", sdp: await r.text() };
      await pc.setRemoteDescription(answer);

      const stream = await navigator.mediaDevices.getUserMedia({ audio:true });
      micTrack = stream.getTracks()[0];
      pc.addTrack(micTrack, stream);  // only once
      micTrack.enabled = false;       // start muted
      console.log("ðŸŽ™ï¸ Mic ready (spacebar to enable)");
    }

    function startTalking() {
      if (micTrack) {
        micTrack.enabled = true;
        console.log("ðŸŽ™ï¸ Talking...");
        timeoutId = setTimeout(stopTalking, 30000); // auto-stop after 30s
      }
    }

    function stopTalking() {
      if (micTrack) {
        micTrack.enabled = false;
        if (timeoutId) clearTimeout(timeoutId);
        console.log("ðŸ”‡ Mic stopped");
      }
    }

    document.addEventListener("keydown", (e) => {
      if (e.code === "Space") startTalking();
    });
    document.addEventListener("keyup", (e) => {
      if (e.code === "Space") stopTalking();
    });

    initRealtime().catch(err => console.error("ðŸ”¥ initRealtime error:", err));
  </script>
</body>
</html>
